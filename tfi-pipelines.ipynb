{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Links\n",
    "- https://www.kaggle.com/c/restaurant-revenue-prediction\n",
    "\n",
    "# Solutions:\n",
    "- 13-th place: https://github.com/bensolucky/TFI\n",
    "- 14-th place: https://github.com/rohanrao91/Kaggle_TFI (stable on both public and private boards)\n",
    "- 32-th place: https://github.com/ITankoyeu/Kaggle_TFI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split, LeaveOneOut\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.gaussian_process import GaussianProcess, GaussianProcessRegressor\n",
    "from sklearn.linear_model import HuberRegressor, ARDRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.base import clone as sk_clone\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "%run dstools/dstools/ml/transformers.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmse(true, pred):\n",
    "    return math.sqrt(mean_squared_error(true, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_test(est):\n",
    "    df = pd.read_csv('train.csv.gz', index_col='Id')\n",
    "    features = df.drop(['revenue'], axis=1)\n",
    "    target = df.revenue\n",
    "    \n",
    "    scores = []\n",
    "    for i in range(100):\n",
    "        m = sk_clone(est)\n",
    "        xtr, xtst, ytr, ytst = train_test_split(features, target, test_size=.2)\n",
    "        m.fit(xtr, ytr)\n",
    "        scorer = make_scorer(rmse)\n",
    "        scores.append(scorer(m, xtst, ytst))\n",
    "\n",
    "    scores = np.array(scores)\n",
    "    print('mean: {mean}, std: {std}'.format(mean=scores.mean(), std=scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def submit(est):\n",
    "    df = pd.read_csv('train.csv.gz', index_col='Id')\n",
    "    features = df.drop(['revenue'], axis=1)\n",
    "    labels = df.revenue\n",
    "\n",
    "    model = est.fit(features, labels)\n",
    "\n",
    "    df_test = pd.read_csv('test.csv.gz', index_col='Id')\n",
    "\n",
    "    y_pred = model.predict(df_test)\n",
    "\n",
    "    res_df = pd.DataFrame({'Prediction': y_pred}, index=df_test.index)\n",
    "    res_df.to_csv('results.csv', index_label='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def outliers_filter(features, target):\n",
    "    threshold = target.mean()+target.std()*3\n",
    "    return features[target < threshold], target[target < threshold]\n",
    "\n",
    "class SamplesFilteringPipeline(BaseEstimator):\n",
    "    def __init__(self, pipeline, samples_filter):\n",
    "        self.pipeline = pipeline\n",
    "        self.samples_filter = samples_filter\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X_filtered, y_filtered = self.samples_filter(X, y)\n",
    "        return self.pipeline.fit(X_filtered, y_filtered)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.pipeline.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.pipeline.predict_proba(X)\n",
    "    \n",
    "def no_outliers_pipeline(est):\n",
    "    return SamplesFilteringPipeline(est, outliers_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def days_to_delta(df):\n",
    "    delta = np.timedelta64(1, 'D')\n",
    "    days_open = (pd.to_datetime('2015-02-01') - pd.to_datetime(df['Open Date'])) / delta\n",
    "    dfc = df.drop('Open Date', axis=1).copy()\n",
    "    dfc['days_open'] = days_open\n",
    "    return dfc\n",
    "\n",
    "df2dict = FunctionTransformer(\n",
    "    lambda x: x.to_dict(orient='records'), validate=False)\n",
    "\n",
    "transf = make_pipeline(\n",
    "    FunctionTransformer(days_to_delta, validate=False),\n",
    "    df2dict,\n",
    "    DictVectorizer(sparse=False),\n",
    ")\n",
    "\n",
    "transf2 = make_pipeline(\n",
    "    FunctionTransformer(days_to_delta, validate=False),\n",
    "    empirical_bayes_encoder_normal_distr(),\n",
    "    Imputer()\n",
    ")\n",
    "\n",
    "transf3 = make_pipeline(\n",
    "    FunctionTransformer(days_to_delta, validate=False),\n",
    "    count_encoder(),\n",
    "    Imputer()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "est1 = no_outliers_pipeline(make_pipeline(\n",
    "    transf,\n",
    "    SelectKBest(f_regression, 20),\n",
    "    RandomForestRegressor(n_jobs=4, n_estimators=100, max_features=0.2, max_depth=2, random_state=1)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 2349991.57899, std: 779557.222073\n",
      "CPU times: user 1min 40s, sys: 11 s, total: 1min 51s\n",
      "Wall time: 2min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "split_test(est1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "est2 = no_outliers_pipeline(make_pipeline(\n",
    "    transf2,\n",
    "    SelectKBest(f_regression, 20),\n",
    "    RandomForestRegressor(n_jobs=4, n_estimators=100, max_features=0.2, max_depth=2, random_state=1)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 2263352.0087537235, std: 709362.6026967816\n",
      "CPU times: user 21.9 s, sys: 3.27 s, total: 25.2 s\n",
      "Wall time: 37.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "split_test(est2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "est22 = no_outliers_pipeline(make_pipeline(\n",
    "    transf3,\n",
    "    SelectKBest(f_regression, 20),\n",
    "    RandomForestRegressor(n_jobs=4, n_estimators=100, max_features=0.2, max_depth=2, random_state=1)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 2289320.651580539, std: 779319.7397884463\n",
      "CPU times: user 31 s, sys: 3.74 s, total: 34.7 s\n",
      "Wall time: 32.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "split_test(est22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "est3 = make_pipeline(\n",
    "    transf,\n",
    "    HuberRegressor(epsilon=1.2),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 2459744.97601, std: 701037.985616\n",
      "CPU times: user 27.6 s, sys: 257 ms, total: 27.8 s\n",
      "Wall time: 17.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "split_test(est3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "est4 = no_outliers_pipeline(make_pipeline(\n",
    "    transf,\n",
    "    HuberRegressor(epsilon=1.2),\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 2477808.29769, std: 747109.15184\n",
      "CPU times: user 28.1 s, sys: 283 ms, total: 28.3 s\n",
      "Wall time: 18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "split_test(est4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "est5 = no_outliers_pipeline(make_pipeline(\n",
    "    transf,\n",
    "    ARDRegression(),\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 2376231.35043, std: 711591.713199\n",
      "CPU times: user 33.2 s, sys: 233 ms, total: 33.4 s\n",
      "Wall time: 20.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "split_test(est5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
